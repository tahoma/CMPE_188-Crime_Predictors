{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Reading Incident Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our initial dataset can be retrieved from this link: <https://data.sfgov.org/api/views/tmnf-yvry/rows.csv?accessType=DOWNLOAD>.\n",
    "\n",
    "It is larger than the maximum 100 MB file size that github allows.  Until we decide how we're going to filter it and can check it in, just make certain it's downloaded into the same directory as the ipython notebook file.\n",
    "\n",
    "Once the dataset is in place, the following code can read in the CSV as a dataframe and report the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./SFPD_Incidents_-_from_1_January_2003.csv')\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Print the entire list of features from original dataset so we can see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to confirm that we're getting the expected data, report the value in the 'Date' column for row 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = df.get_value(0, 'Date')\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a neat way to perform a select to filter rows on a dataframe. Note that I'm creating a smaller dataframe by selecting the rows where the 'Date' column is equal to the date read above for row 0.  Be careful, though, and note that the row indices still match those from the original dataset, which will cause you fits if you're trying to iterate over row indices with the smaller dataset since it no longer has contiguous indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_on_date = df[df.Date == date]\n",
    "df_on_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Mapping Incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "We probably need to be able to do visualizations involving\n",
    "layering over a base map of San Francisco based upon coordinates\n",
    "expressed like we have available in the dataset.\n",
    "\n",
    "Some links:\n",
    "* http://bokeh.pydata.org/en/latest/docs/user_guide/geo.html\n",
    "* https://github.com/pbugnion/gmaps\n",
    "* https://github.com/python-visualization/folium\n",
    "\n",
    "Given that a couple of these required it, I went ahead and grabbed a Google Maps API key for a project named\n",
    "\"CMPE 188 - Crime Predictors\". It is \"AIzaSyAs6Ugy0oz0R5YAxep9-kQ170t0U2fjELQ\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So, here's an attempt with the sample code from the Bokeh-based instructions, chosen because Bokeh appears to be built into the Conda distribution.  Also, the other of couple packages I tried didn't work out very well, as you can see from going back through the commit history.\n",
    "\n",
    "Anyway, please note that I had to run the following command before I could get the inline map to display at all.\n",
    "\n",
    "```\n",
    "jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, output_notebook, show\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, DataRange1d, PanTool, WheelZoomTool, BoxSelectTool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Choose one, I believe.  The first is more reliable, but\n",
    "# the second is more appropriately inline, when it works.\n",
    "#output_file(\"gmap_plot.html\")\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "map_options = GMapOptions(lat=37.761701, lng=-122.421582, map_type=\"roadmap\", zoom=11)\n",
    "\n",
    "plot = GMapPlot(\n",
    "    x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options\n",
    ")\n",
    "plot.title.text = \"San Francisco Police Departments incident locations on \" + date\n",
    "\n",
    "# For GMaps to function, Google requires you obtain and enable an API key:\n",
    "#\n",
    "#     https://developers.google.com/maps/documentation/javascript/get-api-key\n",
    "#\n",
    "# Replace the value below with your personal API key:\n",
    "plot.api_key = \"AIzaSyAs6Ugy0oz0R5YAxep9-kQ170t0U2fjELQ\"\n",
    "\n",
    "# Extract the coordinates for the incidents on the extracted date.\n",
    "my_lats = []\n",
    "my_lons = []\n",
    "for row in df_on_date.itertuples():\n",
    "    my_lats.append(float(row.Y))\n",
    "    my_lons.append(float(row.X))\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=my_lats,\n",
    "        lon=my_lons,\n",
    "    )\n",
    ")\n",
    "\n",
    "circle = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"blue\", fill_alpha=0.8, line_color=None)\n",
    "plot.add_glyph(source, circle)\n",
    "\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "\n",
    "*Tahoma's list of interesting things to experiment with:*\n",
    "\n",
    "* See if clustering would show anything interesting in our dataset.\n",
    "* Make a set out of the category column, and then display its size and elements.\n",
    "* Change the map to display different categories of incident in different colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clustering Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Brief overview - narrowing down the sfpd dataset by given date \n",
    "# and other minor things to get small enough subset for K means algorithm to run on my hardware\n",
    "# for k means, the input must be numeric and the dataframe converted into a matrix to ditch the column headers \n",
    "\n",
    "# please remember, this is really only horseplay\n",
    "\n",
    "reduced_df = df[['Category', 'Descript', 'DayOfWeek', 'Date', 'Time']]\n",
    "\n",
    "#select rows on only 1 day\n",
    "date = reduced_df.get_value(0, 'Date')\n",
    "\n",
    "#filter useless? information\n",
    "reduced_df = reduced_df[reduced_df.Category != \"FRAUD\"]\n",
    "reduced_df = reduced_df[reduced_df.Category != \"NON-CRIMINAL\"]\n",
    "reduced_df = reduced_df[reduced_df.Date == date]\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the number of different description cases out of each category, tells the number of \n",
    "# categorys but not neccesarily the diff descriptions since some are duplicates\n",
    "# found help from this site \n",
    "# http://stackoverflow.com/questions/15411158/pandas-countdistinct-equivalent\n",
    "\n",
    "# for a given day \n",
    "reduced_df.groupby('Category').Descript.nunique()\n",
    "\n",
    "\n",
    "# for the entire dataset\n",
    "df.groupby('Category').Descript.nunique()\n",
    "\n",
    "\n",
    "#take a sample set of features to feed into Kmeans\n",
    "\n",
    "data_df_test = df[['Category', 'Descript']]\n",
    "\n",
    "#data_df_test = data_df_test[data_df_test.Category != \"TREA\"]\n",
    "#data_df_test = data_df_test[data_df_test.Category != \"RECOVERED VEHICLE\"]\n",
    "#data_df_test = data_df_test[data_df_test.Category != \"PORNOGRAPHY/OBSCENE MAT\"]\n",
    "#data_df_test = data_df_test[data_df_test.Category != \"BRIBERY\"]\n",
    "#data_df_test = data_df_test[data_df_test.Category != \"SUICIDE\"]\n",
    "\n",
    "\n",
    "data_df_test.groupby(\"Category\").Descript.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# in order to use K-means, the inputs must be numerical, so we have to discretize the category input\n",
    "# found this post off stackoverflow helpful \n",
    "# http://stackoverflow.com/questions/34915813/convert-text-columns-into-numbers-in-sklearn \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "test_series = reduced_df[reduced_df.columns[:]].apply(le.fit_transform)\n",
    "\n",
    "print(test_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#normalize the input data before using kmeans\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import bokeh.plotting\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "normalized_df = (test_series-test_series.mean())/test_series.std()\n",
    "\n",
    "# remove the date and time columns since LabelEncoder zero'ed all date and times (not sure why)\n",
    "\n",
    "# TMT: They were zero'd because you were normalizing labels to numbers, and the dataframe\n",
    "# was already selected down incidents from the same Date (and, thus, DayOfWeek).\n",
    "\n",
    "del normalized_df[\"DayOfWeek\"]\n",
    "del normalized_df[\"Date\"]\n",
    "\n",
    "# remove the column names by transforming dataframe inot matrix\n",
    "\n",
    "testdata = normalized_df.as_matrix(columns=None)\n",
    "\n",
    "print(testdata)\n",
    "#perform k-means analysis on the reduced data set\n",
    "\n",
    "kmean = KMeans(n_clusters=5) \n",
    "\n",
    "kmean.fit(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plot2 = figure(width=500, height=500, title='CrimeStoppers', x_axis_label = \"category\", y_axis_label = \"descript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#plot centroid / cluster center / group mean for each group\n",
    "\n",
    "clus_xs = []\n",
    "\n",
    "clus_ys = []\n",
    "\n",
    "#we get the  cluster x / y values from the k-means algorithm\n",
    "\n",
    "for entry in kmean.cluster_centers_:\n",
    "\n",
    "   clus_xs.append(entry[0])\n",
    "\n",
    "   clus_ys.append(entry[1])\n",
    "\n",
    "#the cluster center is marked by a circle, with a cross in it\n",
    "\n",
    "plot2.circle_cross(x=clus_xs, y=clus_ys, size=40, fill_alpha=0, line_width=2, color=['red', 'blue', 'purple', 'green', 'yellow'])\n",
    "\n",
    "plot2.text(text = ['something', 'other', 'another', 'yet', 'more'], x=clus_xs, y=clus_ys, text_font_size='30pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i = 0 #counter\n",
    "\n",
    "#begin plotting each petal length / width\n",
    "\n",
    "#We get our x / y values from the original plot data.\n",
    "\n",
    "#The k-means algorithm tells us which 'color' each plot point is,\n",
    "\n",
    "#and therefore which group it is a member of.\n",
    "\n",
    "for sample in testdata:\n",
    "\n",
    "    #\"labels_\" tells us which cluster each plot point is a member of\n",
    "    if kmean.labels_[i] == 0:\n",
    "        plot2.circle(x=sample[0], y=sample[1], size=15, color=\"red\")\n",
    "    if kmean.labels_[i] == 1:\n",
    "        plot2.circle(x=sample[0], y=sample[1], size=15, color=\"blue\")\n",
    "    if kmean.labels_[i] == 2:\n",
    "        plot2.circle(x=sample[0], y=sample[1], size=15, color=\"purple\")\n",
    "    if kmean.labels_[i] == 3:\n",
    "        plot2.circle(x=sample[0], y=sample[1], size=15, color=\"green\")\n",
    "    if kmean.labels_[i] == 4:\n",
    "        plot2.circle(x=sample[0], y=sample[1], size=15, color=\"yellow\")  \n",
    "    i += 1\n",
    "\n",
    "# output using given date, normalization with std dev and 5 categories\n",
    "# the last step, I have been trying to evaluate the messy plot and tweek some parameters\n",
    "\n",
    "bokeh.plotting.show(plot2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
